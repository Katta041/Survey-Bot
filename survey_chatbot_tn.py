import streamlit as st
import pandas as pd
import openai
import os

# --- Configuration ---
# Set page title and layout
st.set_page_config(page_title="Survey Data Chatbot", page_icon="ЁЯЧ│я╕П", layout="wide")

# Load API Key (Priority: Secrets -> Env -> Config)
api_key = None
try:
    if "OPENAI_API_KEY" in st.secrets:
        api_key = st.secrets["OPENAI_API_KEY"]
except Exception:
    pass

if not api_key:
    try:
        import sys
        # Ensure current directory is in path to find framework_config
        if os.getcwd() not in sys.path:
            sys.path.append(os.getcwd())
        from framework_config import OPENAI_API_KEY
        api_key = OPENAI_API_KEY
    except Exception as e:
        print(f"Failed to load from framework_config: {e}")

if not api_key:
    st.error("ЁЯФС API Key Missing! Please add it to `.streamlit/secrets.toml` or `framework_config.py`.")
    st.stop()

os.environ["OPENAI_API_KEY"] = api_key
client = openai.OpenAI(api_key=api_key)

# --- Data Loading ---
# --- Data Loading ---
# Use relative paths for Cloud Deployment
DATA_PATH = "audio_samples/tn_samples/tn_transcribed_metadata_sarvam.csv"

@st.cache_data
def load_data(path):
    if not os.path.exists(path):
        st.error(f"тЭМ Data file not found at: {path}")
        return None
    # Load Transcripts
    df_transcripts = pd.read_csv(path)
    
    # Load Excel Data for Election Columns
    excel_path = "Tamil Nadu/THIRUVOTTIYUR_2026-02-19_to_2026-02-20.xlsx"
    if os.path.exists(excel_path):
        try:
            df_excel = pd.read_excel(excel_path) # Auto-picks first sheet
            # Normalize column names if needed
            # Drop columns from df_transcripts that we will get from Excel
            cols_to_drop = ['Caste', 'Age', 'Gender', 'Q1_MLA', 'Q3_Next_CM']
            for c in cols_to_drop:
                if c in df_transcripts.columns:
                    df_transcripts.drop(columns=[c], inplace=True)
                    
            df = pd.merge(df_transcripts, df_excel, left_on='url', right_on='Audio URL', how='left', suffixes=('', '_excel'))
        except Exception as e:
            st.error(f"Error loading Excel data: {e}")
            df = df_transcripts # Fallback
    else:
        st.warning(f"тЪая╕П Excel data not found at: {excel_path}. Using transcripts only.")
        df = df_transcripts

    # Ensure relevant columns are string type for filtering
    # Map long questions to aliases for easier access
    column_aliases = {
        'Q1: роЙроЩрпНроХро│рпН родрпКроХрпБродро┐ роЪроЯрпНроЯрооройрпНро▒ роЙро▒рпБрокрпНрокро┐ройро░ро┐ройрпН (MLA) роЪрпЖропро▓рпНрокро╛роЯрпБроХро│ро╛ро▓рпН роирпАроЩрпНроХро│рпН родро┐ро░рпБрокрпНродро┐ропро╛роХ роЙро│рпНро│рпАро░рпНроХро│ро╛?/ Are you satisfied with the performance of your constituency MLA?': 'MLA_Satisfaction',
        'Q2: ро╡ро░ро╡ро┐ро░рпБроХрпНроХрпБроорпН роЪроЯрпНроЯрооройрпНро▒ родрпЗро░рпНродро▓ро┐ро▓рпН роЖроЯрпНроЪро┐ рооро╛ро▒рпНро▒роорпН родрпЗро╡рпИропрпЖрой роирпАроЩрпНроХро│рпН роиро┐ройрпИроХрпНроХро┐ро▒рпАро░рпНроХро│ро╛?/ Do you feel a change in government is needed in the coming assembly Elections?': 'Desires_Change',
        'Q3: родрооро┐ро┤рпНроиро╛роЯрпНроЯро┐ройрпН роЕроЯрпБродрпНрод роорпБродро▓роорпИроЪрпНроЪро░ро╛роХ роирпАроЩрпНроХро│рпН ропро╛ро░рпИ роЖродро░ро┐роХрпНроХро┐ро▒рпАро░рпНроХро│рпН?/ Whom do you support as Tamil NaduтАЩs next Chief Minister?': 'Next_CM',
        'Q4: ро╡ро░ро╡ро┐ро░рпБроХрпНроХрпБроорпН роЪроЯрпНроЯрооройрпНро▒ родрпЗро░рпНродро▓ро┐ро▓рпН роирпАроЩрпНроХро│рпН роОроирпНродроХрпН роХроЯрпНроЪро┐ / роХрпВроЯрпНроЯрогро┐роХрпНроХрпБ ро╡ро╛роХрпНроХро│ро┐роХрпНроХ роЙро│рпНро│рпАро░рпНроХро│рпН?/ Which party/ alliance will you vote in the upcoming assembly elections?': 'Vote_2026',
        'Q8: роорпБроирпНродрпИроп (2021) роЪроЯрпНроЯрооройрпНро▒ родрпЗро░рпНродро▓ро┐ро▓рпН роирпАроЩрпНроХро│рпН роОроирпНродроХрпН роХроЯрпНроЪро┐ / роХрпВроЯрпНроЯрогро┐роХрпНроХрпБ ро╡ро╛роХрпНроХро│ро┐родрпНродрпАро░рпНроХро│рпН?/ Which party did you vote in the previous(2021) assembly election?': 'Vote_2021',
        'Q13: роЪро╛родро┐/Caste': 'Caste',
        'Q9: рокро╛ро▓ро┐ройроорпН/Gender': 'Gender',
        'Q10: ро╡ропродрпБ рокро┐ро░ро┐ро╡рпБ/Age Group': 'Age_Group'
    }
    df.rename(columns=column_aliases, inplace=True)

    columns_to_str = ['MLA_Satisfaction', 'Desires_Change', 'Next_CM', 'Vote_2026', 'Vote_2021', 'Caste', 'Gender', 'Age_Group', 'transcript', 'QC Comment']
    for col in columns_to_str:
        if col in df.columns:
            df[col] = df[col].astype(str)
            
    # Ensure sample_id exists for pagination
    if 'sample_id' not in df.columns:
        df['sample_id'] = df.index.astype(str)
        
    # Deduplicate columns if any still exist
    df = df.loc[:, ~df.columns.duplicated()]
        
    return df

df = load_data(DATA_PATH)
# ... (rest of filtering)

# Initialise Chat History
if "messages" not in st.session_state:
    st.session_state.messages = []
if "last_search" not in st.session_state:
    st.session_state.last_search = {"keywords": [], "topic": "", "cited_ids": []}

# --- Sidebar & Settings ---
with st.sidebar:
    st.title("Settings тЪЩя╕П")
    language = st.radio("Response Language / роорпКро┤ро┐:", ["English", "Tamil (родрооро┐ро┤рпН)"])
    st.markdown("---")
    st.markdown("**Dataset Info:**")
    if df is None:
        st.error("тЭМ Failed to load data. Please check if the data files exist in the repository.")
        st.stop()
    
    # Display Metrics
    st.write(f"Total Records: {len(df)}")
    
    st.markdown("---")
    st.subheader("ЁЯТб Suggested Questions")
    
    # Bilingual Suggestions
    first_batch = {
        "English": [
            "Are people satisfied with the MLA's performance?",
            "Who do people support as the next Chief Minister?",
            "Why do people want a change in government?",
            "What did people say about Vijay (TVK)?"
        ],
        "Tamil (родрооро┐ро┤рпН)": [
            "роОроорпН.роОро▓рпН.роП ро╡ро┐ройрпН роЪрпЖропро▓рпНрокро╛роЯрпБроХро│ро┐ро▓рпН роороХрпНроХро│рпН родро┐ро░рпБрокрпНродро┐ роЕроЯрпИроирпНродрпБро│рпНро│ро╛ро░рпНроХро│ро╛?",
            "роЕроЯрпБродрпНрод роорпБродро▓роорпИроЪрпНроЪро░ро╛роХ роороХрпНроХро│рпН ропро╛ро░рпИ роЖродро░ро┐роХрпНроХро┐ро▒ро╛ро░рпНроХро│рпН?",
            "роороХрпНроХро│рпН роПройрпН роЖроЯрпНроЪро┐ рооро╛ро▒рпНро▒родрпНродрпИ ро╡ро┐ро░рпБроорпНрокрпБроХро┐ро▒ро╛ро░рпНроХро│рпН?",
            "ро╡ро┐роЬропрпН (род.ро╡рпЖ.роХ) рокро▒рпНро▒ро┐ роороХрпНроХро│рпН роОройрпНрой роЪрпКро▓рпНроХро┐ро▒ро╛ро░рпНроХро│рпН?"
        ]
    }
    
    if "more_questions" not in st.session_state:
        st.session_state.more_questions = False

    suggestions = first_batch
    
    second_batch = {
        "English": [
            "What are the main issues faced by women (Female voters)?",
            "How many voters support DMK alliance?",
            "Summarize the sentiment towards the current CM.",
            "Who is considered the most accessible leader?"
        ],
        "Tamil (родрооро┐ро┤рпН)": [
            "рокрпЖрогрпНроХро│рпН роОродро┐ро░рпНроХрпКро│рпНро│рпБроорпН роорпБроХрпНроХро┐роп рокро┐ро░роЪрпНроЪройрпИроХро│рпН роОройрпНрой?",
            "родро┐роорпБроХ роХрпВроЯрпНроЯрогро┐роХрпНроХрпБ роОро╡рпНро╡ро│ро╡рпБ рокрпЗро░рпН роЖродро░ро╡рпБ роЕро│ро┐роХрпНроХро┐ройрпНро▒ройро░рпН?",
            "родро▒рпНрокрпЛродрпИроп роорпБродро▓рпНро╡ро░рпИрокрпН рокро▒рпНро▒ро┐роп роороХрпНроХро│ро┐ройрпН роХро░рпБродрпНродрпИ роЪрпБро░рпБроХрпНроХрооро╛роХроХрпН роХрпВро▒ро╡рпБроорпН.",
            "роороХрпНроХро│рпН роОро│ро┐родро╛роХ роЕрогрпБроХроХрпНроХрпВроЯро┐роп родро▓рпИро╡ро░ро╛роХ ропро╛ро░рпН роХро░рпБродрокрпНрокроЯрпБроХро┐ро▒ро╛ро░рпН?"
        ]
    }
    
    selected_lang = "Tamil (родрооро┐ро┤рпН)" if "Tamil" in language else "English"
    
    def render_buttons(q_list):
        for q in q_list:
            if st.button(q):
                st.session_state.messages.append({"role": "user", "content": q})
                st.rerun()

    render_buttons(first_batch[selected_lang])
    
    if st.checkbox("Show More Complex Questions тЮХ"):
        render_buttons(second_batch[selected_lang])

# --- Main Interface ---
st.title("ЁЯЧ│я╕П Survey Data Intelligence Chatbot (TN)")
st.markdown("""
Ask questions about the survey data. 
- **Quantitative:** "How many people in Vanniyar caste support TVK?"
- **Qualitative:** "What are people saying about the MLA's performance?"
""")

# Display Chat History
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- Logic: Query Processing ---
def generate_response(user_query, lang, history):
    unique_castes = df['Caste'].unique().tolist() if 'Caste' in df.columns else []
    unique_next_cm = df['Next_CM'].unique().tolist() if 'Next_CM' in df.columns else []
    unique_vote = df['Vote_2026'].unique().tolist() if 'Vote_2026' in df.columns else []
    
    system_prompt = f"""
    You are a data analyst assistant for a political survey dataset in Tamil Nadu.
    The dataset has columns: 
    - `MLA_Satisfaction` (Are you satisfied with the MLA?)
    - `Desires_Change` (Do you feel a change in govt is needed?)
    - `Next_CM` (Whom do you support as next CM?)
    - `Vote_2026` (Which party will you vote for?)
    - `Caste`, `Age_Group`, `Gender`
    - `QC Comment`
    - `transcript` (Tamil Audio Transcript)
    
    ### DATASET VOCABULARY (Colloquial Tamil Terms):
    - **Infrastructure:**
      - Roads: "роЪро╛ро▓рпИ" (Road), "ро░рпЛроЯрпБ" (Road), "роХрпБро┤ро┐роХро│рпН" (Potholes)
      - Water: "родрогрпНрогрпАро░рпН" (Water), "роХрпБроЯро┐роирпАро░рпН" (Drinking Water), "роХрпБро┤ро╛ропрпН" (Tap)
      - Power: "рооро┐ройрпНроЪро╛ро░роорпН" (Electricity), "роХро░рогрпНроЯрпН" (Current)
    - **Schemes:**
      - "родро┐роЯрпНроЯроорпН" (Scheme), "роЙродро╡ро┐родрпНродрпКроХрпИ" (Pension), "ро░рпЗро╖ройрпН" (Ration)
    - **Leaders & Parties:**
      - "родро┐роорпБроХ" (DMK), "роЕродро┐роорпБроХ" (ADMK), "ро╡ро┐роЬропрпН" (Vijay), "род.ро╡рпЖ.роХ" (TVK), "ро╕рпНроЯро╛ро▓ро┐ройрпН" (Stalin), "роОроЯрокрпНрокро╛роЯро┐" (Edappadi)
      - "роОроорпН.роОро▓рпН.роП" (MLA), "роорпБродро▓рпНро╡ро░рпН" (CM), "роХроЯрпНроЪро┐" (Party)
    - **Sentiment:**
      - Positive: "роиро▓рпНро▓ро╛ роЗро░рпБроХрпНроХрпБ" (Good), "рокро░ро╡ро╛ропро┐ро▓рпНро▓рпИ" (Okay/Not bad), "родро┐ро░рпБрокрпНродро┐" (Satisfied)
      - Negative: "роорпЛроЪроорпН" (Bad), "роТройрпНройрпБроорпН роЗро▓рпНро▓" (Nothing), "родро┐ро░рпБрокрпНродро┐ роЗро▓рпНро▓рпИ" (Not satisfied)
      - Change: "рооро╛ро▒рпНро▒роорпН родрпЗро╡рпИ" (Need change), "ро╡рпЗрогрпНроЯро╛роорпН" (Don't want)

    ### SCHEMA MAPPING:
    - **Caste:** {unique_castes}
    - **Next_CM:** {unique_next_cm}
    - **Vote_2026:** {unique_vote}
    
    Current User Query: "{user_query}"
    Output Language: {lang}
    Previous Context: {history[-3:] if history else "None"}

    DECISION LOGIC:
    1. If the user asks for a COUNT, AGGREGATION, or STATISTIC (e.g., "How many voted for TVK?", "Distribution of next CM"):
       - Return a JSON object with: {{"type": "code", "code": "..."}}
       - The 'code' must be valid Python/Pandas code that operates on a dataframe named `df`.
       - Use column aliases `Next_CM`, `Vote_2026`, etc.
       - **CRITICAL:** Use `.str.contains` or lists for filtering. Because columns contain Tamil/English mixed like 'ро╡ро┐роЬропрпН (родрооро┐ро┤роХроорпН ро╡рпЖро▒рпНро▒ро┐ роХро┤роХроорпН)/ Vijay (TVK)' use `.str.contains('Vijay')` or `.str.contains('ро╡ро┐роЬропрпН')`.
       - **CRITICAL:** If using multiple lines of code, you MUST assign the final answer to a variable named `result`! Example: `result = {{"Vijay": vijay_count, "Stalin": stalin_count}}`
       - **CRITICAL DEFENSIVE PROGRAMMING:** The dataset is highly categorical and some combinations (like "Vanniyar") might have ZERO rows. Therefore, if you use `.idxmax()`, you MUST check if the filtered series is empty first OR wrap it in a try-except. Example: `result = counts.idxmax() if not counts.empty else "No matching data"`
       - Provide zero instead of causing `KeyError`. Replace `.shape[0]` or `.sum()` with `0` if empty.
       - **CRITICAL STRING TYPES:** ALL columns are strings, even `MLA_Satisfaction` (Yes/No). You cannot use boolean filtering like `df[df['MLA_Satisfaction']]`. You MUST use `df[df['MLA_Satisfaction'] == 'Yes']`.
       - **CRITICAL SYNTAX:** Never write invalid python syntax. Specifically, do not write malformed dictionary comprehensions. If you need to clean dictionaries, use a simple `for` loop before assigning to `result`.
    
    2. If the user asks for QUALITATIVE info (e.g., "Why do people want to change the MLA?"):
       - Return a JSON object with: {{"type": "search", "keywords": ["..."], "topic": "..."}}
       - The 'keywords' should be Tamil terms.
    
    3. If the user asks for MORE info on the previous topic:
       - Return a JSON object with: {{"type": "more_results"}}
    
    4. If general chat or follow-up:
       - Return {{"type": "chat", "response": "..."}}
    """
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_query}
            ],
            response_format={"type": "json_object"}
        )
        return response.choices[0].message.content
    except Exception as e:
        return f'{{"type": "error", "message": "{str(e)}"}}'

def execute_pandas_code(code, df):
    try:
        local_vars = {"df": df, "pd": pd}
        # Try evaluating as a single expression first
        try:
            result = eval(code, {}, local_vars)
            return result
        except SyntaxError:
            # If it's a multi-line statement, use exec
            exec(code, {}, local_vars)
            if 'result' in local_vars:
                return local_vars['result']
            # Find the last defined variable that isn't a module
            result = None
            for key, val in reversed(list(local_vars.items())):
                if key not in ['df', 'pd'] and not isinstance(val, type(pd)):
                    result = val
                    break
            return result
    except Exception as e:
        return f"Error executing code: {e}"

def search_transcripts(keywords, topic, df, exclude_ids=[]):
    mask = df['transcript'].str.contains('|'.join(keywords), case=False, na=False)
    matches = df[mask]
    
    if exclude_ids:
        matches = matches[~matches['sample_id'].isin(exclude_ids)]
    
    if matches.empty:
        return None, [], 0
    
    matches['length'] = matches['transcript'].str.len()
    matches = matches.sort_values('length', ascending=False)
    
    total_matches = len(matches)
    sample_matches = matches.head(3)
    context_text = ""
    citations = []
    
    for idx, row in sample_matches.iterrows():
        sid = row.get('sample_id', str(idx))
        text = row['transcript']
        if len(text) > 1500:
            text = text[:1500] + "... (truncated)"
        context_text += f"[Sample {sid}]: {text}\n\n"
        citations.append(sid)
        
    return context_text, citations, total_matches

def synthesize_qualitative_answer(query, context, lang):
    prompt = f"""
    User Query: {query}
    Context (Tamil Transcripts):
    {context}
    
    Task: Summarize the opinions/information found in these transcripts regarding the query.
    - The transcripts are in Tamil.
    - Cite the source using [Sample ID] for every point.
    - Answer in: {lang}
    - If the context mentions the topic but has no clear opinion, state "Mentioned without specific opinion."
    """
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content
    except openai.RateLimitError:
        return "тЪая╕П **System Busy:** Rate limit hit. I have reduced the context size, try asking again."
    except Exception as e:
        return f"Error generating answer: {str(e)}"

if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
    pass

if prompt := st.chat_input("Ask a question..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.rerun()

if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
    prompt = st.session_state.messages[-1]["content"]
    
    with st.chat_message("assistant"):
        with st.spinner("Analyzing data..."):
            import json
            
            history_summary = [{"role": m["role"], "content": m["content"]} for m in st.session_state.messages]
            decision_json = generate_response(prompt, language, history_summary)
            decision = json.loads(decision_json)
            
            response_text = ""
            
            if decision["type"] == "code":
                code = decision["code"]
                result = execute_pandas_code(code, df)
                
                if "Error executing code" in str(result):
                     st.error(f"Code Execution Failed:\n{result}")
                     st.code(code, language="python")
                     response_text = "Sorry, I couldn't calculate that due to a code error."
                else:
                    final_prompt = (
                        f"User Question: '{prompt}'\n"
                        f"Data Answer: {result}\n"
                        f"Task: Respond to the user naturally in {language}.\n"
                        f"- Do NOT mention 'code execution', 'dataframe', or 'analysis'.\n"
                        f"- Just state the answer clearly and conversationally."
                    )
                    final_res = client.chat.completions.create(
                        model="gpt-4o",
                        messages=[{"role": "user", "content": final_prompt}]
                    )
                    response_text = final_res.choices[0].message.content
                
            elif decision["type"] == "search" or decision.get("type") == "more_results":
                if decision["type"] == "search":
                    keywords = decision["keywords"]
                    topic = decision["topic"]
                    
                    english_to_tamil = {
                        "ysrcp": ["родро┐роорпБроХ", "DMK"], # Mapped for analogy, though it's TN so DMK
                        "dmk": ["родро┐роорпБроХ", "ро╕рпНроЯро╛ро▓ро┐ройрпН", "роЙродропроиро┐родро┐"],
                        "admk": ["роЕродро┐роорпБроХ", "роОроЯрокрпНрокро╛роЯро┐", "роЗро░роЯрпНроЯрпИ роЗро▓рпИ"],
                        "tvk": ["род.ро╡рпЖ.роХ", "ро╡ро┐роЬропрпН", "родро│рокродро┐"],
                        "stalin": ["ро╕рпНроЯро╛ро▓ро┐ройрпН", "роорпБродро▓рпНро╡ро░рпН"],
                        "vijay": ["ро╡ро┐роЬропрпН", "роЬрпЛроЪрокрпН ро╡ро┐роЬропрпН"],
                        "mla": ["роОроорпН.роОро▓рпН.роП", "роЪроЯрпНроЯрооройрпНро▒ роЙро▒рпБрокрпНрокро┐ройро░рпН"],
                        "performance": ["роЪрпЖропро▓рпНрокро╛роЯрпБ", "родро┐ро░рпБрокрпНродро┐", "рокрогро┐"],
                        "good": ["роиро▓рпНро▓ро╛ роЗро░рпБроХрпНроХрпБ", "рокро░ро╡ро╛ропро┐ро▓рпНро▓рпИ", "родро┐ро░рпБрокрпНродро┐"],
                        "bad": ["роорпЛроЪроорпН", "родро┐ро░рпБрокрпНродро┐ роЗро▓рпНро▓рпИ", "роТройрпНройрпБроорпН роЗро▓рпНро▓"],
                        "change": ["рооро╛ро▒рпНро▒роорпН родрпЗро╡рпИ", "ро╡рпЗрогрпНроЯро╛роорпН", "рокрпБродрпБроЪрпБ"],
                        "water": ["родрогрпНрогрпАро░рпН", "роХрпБроЯро┐роирпАро░рпН", "роХрпБро┤ро╛ропрпН"],
                        "roads": ["роЪро╛ро▓рпИ", "ро░рпЛроЯрпБ", "роХрпБро┤ро┐роХро│рпН"],
                        "power": ["рооро┐ройрпНроЪро╛ро░роорпН", "роХро░рогрпНроЯрпН"],
                        "scheme": ["родро┐роЯрпНроЯроорпН", "роЙродро╡ро┐", "ро░рпЗро╖ройрпН"]
                    }
                    
                    expanded_keywords = set(keywords)
                    for k in keywords:
                        k_lower = k.lower()
                        for eng_key, tam_vals in english_to_tamil.items():
                            if eng_key in k_lower:
                                expanded_keywords.update(tam_vals)
                    
                    keywords = list(expanded_keywords)

                    exclude_ids = []
                    # Reset session state
                    st.session_state.last_search = {"keywords": keywords, "topic": topic, "cited_ids": []}
                else:
                    # More Results (Pagination)
                    keywords = st.session_state.last_search["keywords"]
                    topic = st.session_state.last_search["topic"]
                    exclude_ids = st.session_state.last_search["cited_ids"]
                    if not keywords:
                        response_text = "I don't have a previous search context to load more results for."
                        keywords = [] # Break

                context, citations, total_matches = search_transcripts(keywords, topic, df, exclude_ids)
                
                if context:
                    # Update cited IDs
                    st.session_state.last_search["cited_ids"].extend(citations)
                    
                    if decision["type"] == "more_results":
                        response_text = synthesize_qualitative_answer(f"Provide MORE details on {topic} (different from previous)", context, language)
                    else:
                        response_text = synthesize_qualitative_answer(prompt, context, language)
                else:
                    if decision["type"] == "more_results":
                         response_text = f"No *more* transcripts found for '{topic}'."
                    else:
                         response_text = f"No transcripts found containing keywords: {', '.join(keywords)}"
            
            else: # Chat or Error
                response_text = decision.get("response", decision.get("message", "Error processing request."))

            st.markdown(response_text)
            st.session_state.messages.append({"role": "assistant", "content": response_text})

            # Debug Info
            with st.expander("ЁЯЫая╕П Debug Info (Internal State)"):
                st.write(f"**Decision Type:** {decision.get('type')}")
                if decision.get("type") in ["search", "more_results"]:
                    st.write(f"**Topic:** {st.session_state.last_search.get('topic')}")
                    st.write(f"**Keywords:** {st.session_state.last_search.get('keywords')}")
                    st.write(f"**Total Matches Available:** {total_matches if 'total_matches' in locals() else 'N/A'}")
                    st.write(f"**Cited IDs (Previous + New):** {st.session_state.last_search.get('cited_ids')}")
                    st.text_area("Context Sent to LLM:", value=context if context else "None", height=200)
                    # st.write(f"**Matches Found:** {len(context) if context else 0}")

